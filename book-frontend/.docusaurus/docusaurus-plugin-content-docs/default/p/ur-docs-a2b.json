{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"category","label":"Module 1 - ROS 2 Nervous System","items":[{"type":"link","href":"/ur/docs/module-1-ros2-nervous-system/ros2-fundamentals","label":"Chapter 1: ROS 2 Fundamentals","docId":"module-1-ros2-nervous-system/ros2-fundamentals","unlisted":false},{"type":"link","href":"/ur/docs/module-1-ros2-nervous-system/python-agents-with-rclpy","label":"Chapter 2: Python Agents with rclpy","docId":"module-1-ros2-nervous-system/python-agents-with-rclpy","unlisted":false},{"type":"link","href":"/ur/docs/module-1-ros2-nervous-system/humanoid-robot-description-urdf","label":"Chapter 3: Humanoid Robot Description with URDF","docId":"module-1-ros2-nervous-system/humanoid-robot-description-urdf","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 2 - The Digital Twin","items":[{"type":"link","href":"/ur/docs/module-2/digital-twins","label":"Chapter 4: The Digital Twin","docId":"module-2/digital-twins","unlisted":false},{"type":"link","href":"/ur/docs/module-2/unity-visualization","label":"Chapter 5: Visualizing the Robot in Unity","docId":"module-2/unity-visualization","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 3 - The AI-Robot Brain (NVIDIA Isaac)","items":[{"type":"link","href":"/ur/docs/module-3-ai-robot-brain/isaac-overview","label":"Chapter 6: Understanding NVIDIA Isaac and Physical AI","docId":"module-3-ai-robot-brain/isaac-overview","unlisted":false},{"type":"link","href":"/ur/docs/module-3-ai-robot-brain/isaac-sim","label":"Isaac Sim: Photorealistic Simulation and Synthetic Data","docId":"module-3-ai-robot-brain/isaac-sim","unlisted":false},{"type":"link","href":"/ur/docs/module-3-ai-robot-brain/isaac-ros","label":"Isaac ROS: VSLAM and Perception Acceleration","docId":"module-3-ai-robot-brain/isaac-ros","unlisted":false},{"type":"link","href":"/ur/docs/module-3-ai-robot-brain/nav2-humanoids","label":"Chapter 9: \"Nav2: Path Planning for Humanoid Robots\"","docId":"module-3-ai-robot-brain/nav2-humanoids","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 4 - Vision-Language-Action (VLA)","items":[{"type":"link","href":"/ur/docs/module-4-vla/vla-overview","label":"Chapter 10:  Vision-Language-Action (VLA)","docId":"module-4-vla/vla-overview","unlisted":false},{"type":"link","href":"/ur/docs/module-4-vla/voice-to-action","label":"Chapter 11: Voice-to-Action with Whisper","docId":"module-4-vla/voice-to-action","unlisted":false},{"type":"link","href":"/ur/docs/module-4-vla/llm-task-planning","label":"Chapter 12: LLM-Based Task Planning to ROS 2","docId":"module-4-vla/llm-task-planning","unlisted":false},{"type":"link","href":"/ur/docs/module-4-vla/autonomous-pipeline","label":"Chapter 13: Capstone: Autonomous Humanoid Pipeline","docId":"module-4-vla/autonomous-pipeline","unlisted":false}],"collapsed":true,"collapsible":true}]},"docs":{"module-1-ros2-nervous-system/humanoid-robot-description-urdf":{"id":"module-1-ros2-nervous-system/humanoid-robot-description-urdf","title":"Chapter 3: Humanoid Robot Description with URDF","description":"We've learned how ROS 2 nodes communicate, but how do they know what the robot's body actually looks like? This is where the Unified Robot Description Format (URDF) comes in. URDF is an XML file format used in ROS to describe all the physical elements of a robot.","sidebar":"tutorialSidebar"},"module-1-ros2-nervous-system/python-agents-with-rclpy":{"id":"module-1-ros2-nervous-system/python-agents-with-rclpy","title":"Chapter 2: Python Agents with rclpy","description":"Now that we understand the fundamental concepts of ROS 2, let's put them into practice. This chapter will show you how to write your own ROS 2 nodes using Python, the language of choice for many AI and robotics applications. We will use the rclpy library, which is the official ROS 2 client library for Python.","sidebar":"tutorialSidebar"},"module-1-ros2-nervous-system/ros2-fundamentals":{"id":"module-1-ros2-nervous-system/ros2-fundamentals","title":"Chapter 1: ROS 2 Fundamentals","description":"Welcome to the \"nervous system\" of modern robotics. This chapter introduces the foundational concepts of the Robot Operating System 2 (ROS 2), the middleware that enables communication and data transfer between all the different software components of a robot.","sidebar":"tutorialSidebar"},"module-2/digital-twins":{"id":"module-2/digital-twins","title":"Chapter 4: The Digital Twin","description":"Welcome to the second module in our series on Physical AI and Humanoid Robotics. In this module, we'll dive deep into the concept of the Digital Twin.","sidebar":"tutorialSidebar"},"module-2/unity-visualization":{"id":"module-2/unity-visualization","title":"Chapter 5: Visualizing the Robot in Unity","description":"This tutorial explains how to set up a Unity scene to act as a high-fidelity, interactive visualizer for our Gazebo simulation.","sidebar":"tutorialSidebar"},"module-3-ai-robot-brain/isaac-overview":{"id":"module-3-ai-robot-brain/isaac-overview","title":"Chapter 6: Understanding NVIDIA Isaac and Physical AI","description":"NVIDIA Isaac represents a powerful and comprehensive platform designed to accelerate the development and deployment of AI-powered robots. It serves as a cornerstone for what is increasingly known as Physical AI, which focuses on intelligent systems capable of interacting with and perceiving the real world, rather than just operating in digital domains.","sidebar":"tutorialSidebar"},"module-3-ai-robot-brain/isaac-ros":{"id":"module-3-ai-robot-brain/isaac-ros","title":"Isaac ROS: VSLAM and Perception Acceleration","description":"NVIDIA Isaac ROS is a collection of hardware-accelerated packages for ROS 2, specifically designed to boost the performance of robotics applications. It leverages the power of NVIDIA GPUs to provide significant acceleration for computationally intensive tasks, particularly in the areas of perception and navigation, which are critical for autonomous robots, including humanoid platforms.","sidebar":"tutorialSidebar"},"module-3-ai-robot-brain/isaac-sim":{"id":"module-3-ai-robot-brain/isaac-sim","title":"Isaac Sim: Photorealistic Simulation and Synthetic Data","description":"NVIDIA Isaac Sim is a powerful and scalable robotics simulation application built on the NVIDIA Omniverse platform. It is a critical component in the development of AI-powered robots, offering a highly realistic virtual environment for design, testing, and training without the constraints and costs associated with physical hardware.","sidebar":"tutorialSidebar"},"module-3-ai-robot-brain/nav2-humanoids":{"id":"module-3-ai-robot-brain/nav2-humanoids","title":"Chapter 9: \"Nav2: Path Planning for Humanoid Robots\"","description":"Nav2 (Navigation2) is the ROS 2-native navigation stack, providing a complete framework for autonomous mobile robots to navigate complex environments. While initially designed for wheeled and tracked robots, its modular architecture and advanced capabilities make it adaptable and highly relevant for path planning in more complex platforms, such as humanoid robots.","sidebar":"tutorialSidebar"},"module-4-vla/autonomous-pipeline":{"id":"module-4-vla/autonomous-pipeline","title":"Chapter 13: Capstone: Autonomous Humanoid Pipeline","description":"This chapter covers the integration of Voice-to-Action and LLM Task Planning into an end-to-end autonomous pipeline for humanoid robots.","sidebar":"tutorialSidebar"},"module-4-vla/llm-task-planning":{"id":"module-4-vla/llm-task-planning","title":"Chapter 12: LLM-Based Task Planning to ROS 2","description":"This chapter covers using Large Language Models (LLMs) for task planning and generating ROS 2 actions.","sidebar":"tutorialSidebar"},"module-4-vla/vla-overview":{"id":"module-4-vla/vla-overview","title":"Chapter 10:  Vision-Language-Action (VLA)","description":"This module introduces Vision-Language-Action (VLA) systems for humanoid robots.","sidebar":"tutorialSidebar"},"module-4-vla/voice-to-action":{"id":"module-4-vla/voice-to-action","title":"Chapter 11: Voice-to-Action with Whisper","description":"This chapter covers converting voice commands into robot actions using Whisper.","sidebar":"tutorialSidebar"}}}}