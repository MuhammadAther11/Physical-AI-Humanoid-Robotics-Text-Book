{"allContent":{"docusaurus-plugin-css-cascade-layers":{},"docusaurus-plugin-content-docs":{"default":{"loadedVersions":[{"versionName":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","path":"/docs","tagsPath":"/docs/tags","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs","isLast":true,"routePriority":-1,"sidebarFilePath":"C:\\Users\\us\\Desktop\\new-Hackathon\\Physical-AI-Humanoid-Robotics-Text-Book\\book-frontend\\sidebars.ts","contentPath":"C:\\Users\\us\\Desktop\\new-Hackathon\\Physical-AI-Humanoid-Robotics-Text-Book\\book-frontend\\docs","docs":[{"id":"module-1-ros2-nervous-system/humanoid-robot-description-urdf","title":"Chapter 3: Humanoid Robot Description with URDF","description":"We've learned how ROS 2 nodes communicate, but how do they know what the robot's body actually looks like? This is where the Unified Robot Description Format (URDF) comes in. URDF is an XML file format used in ROS to describe all the physical elements of a robot.","source":"@site/docs/module-1-ros2-nervous-system/03-humanoid-robot-description-urdf.md","sourceDirName":"module-1-ros2-nervous-system","slug":"/module-1-ros2-nervous-system/humanoid-robot-description-urdf","permalink":"/docs/module-1-ros2-nervous-system/humanoid-robot-description-urdf","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-1-ros2-nervous-system/03-humanoid-robot-description-urdf.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 2: Python Agents with rclpy","permalink":"/docs/module-1-ros2-nervous-system/python-agents-with-rclpy"},"next":{"title":"Chapter 4: The Digital Twin","permalink":"/docs/module-2/digital-twins"}},{"id":"module-1-ros2-nervous-system/python-agents-with-rclpy","title":"Chapter 2: Python Agents with rclpy","description":"Now that we understand the fundamental concepts of ROS 2, let's put them into practice. This chapter will show you how to write your own ROS 2 nodes using Python, the language of choice for many AI and robotics applications. We will use the rclpy library, which is the official ROS 2 client library for Python.","source":"@site/docs/module-1-ros2-nervous-system/02-python-agents-with-rclpy.md","sourceDirName":"module-1-ros2-nervous-system","slug":"/module-1-ros2-nervous-system/python-agents-with-rclpy","permalink":"/docs/module-1-ros2-nervous-system/python-agents-with-rclpy","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-1-ros2-nervous-system/02-python-agents-with-rclpy.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 1: ROS 2 Fundamentals","permalink":"/docs/module-1-ros2-nervous-system/ros2-fundamentals"},"next":{"title":"Chapter 3: Humanoid Robot Description with URDF","permalink":"/docs/module-1-ros2-nervous-system/humanoid-robot-description-urdf"}},{"id":"module-1-ros2-nervous-system/ros2-fundamentals","title":"Chapter 1: ROS 2 Fundamentals","description":"Welcome to the \"nervous system\" of modern robotics. This chapter introduces the foundational concepts of the Robot Operating System 2 (ROS 2), the middleware that enables communication and data transfer between all the different software components of a robot.","source":"@site/docs/module-1-ros2-nervous-system/01-ros2-fundamentals.md","sourceDirName":"module-1-ros2-nervous-system","slug":"/module-1-ros2-nervous-system/ros2-fundamentals","permalink":"/docs/module-1-ros2-nervous-system/ros2-fundamentals","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-1-ros2-nervous-system/01-ros2-fundamentals.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"tutorialSidebar","next":{"title":"Chapter 2: Python Agents with rclpy","permalink":"/docs/module-1-ros2-nervous-system/python-agents-with-rclpy"}},{"id":"module-2/digital-twins","title":"Chapter 4: The Digital Twin","description":"Welcome to the second module in our series on Physical AI and Humanoid Robotics. In this module, we'll dive deep into the concept of the Digital Twin.","source":"@site/docs/module-2/01-digital-twins.md","sourceDirName":"module-2","slug":"/module-2/digital-twins","permalink":"/docs/module-2/digital-twins","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-2/01-digital-twins.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 3: Humanoid Robot Description with URDF","permalink":"/docs/module-1-ros2-nervous-system/humanoid-robot-description-urdf"},"next":{"title":"Chapter 5: Visualizing the Robot in Unity","permalink":"/docs/module-2/unity-visualization"}},{"id":"module-2/unity-visualization","title":"Chapter 5: Visualizing the Robot in Unity","description":"This tutorial explains how to set up a Unity scene to act as a high-fidelity, interactive visualizer for our Gazebo simulation.","source":"@site/docs/module-2/02-unity-visualization.md","sourceDirName":"module-2","slug":"/module-2/unity-visualization","permalink":"/docs/module-2/unity-visualization","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-2/02-unity-visualization.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 4: The Digital Twin","permalink":"/docs/module-2/digital-twins"},"next":{"title":"Chapter 6: Understanding NVIDIA Isaac and Physical AI","permalink":"/docs/module-3-ai-robot-brain/isaac-overview"}},{"id":"module-3-ai-robot-brain/isaac-overview","title":"Chapter 6: Understanding NVIDIA Isaac and Physical AI","description":"NVIDIA Isaac represents a powerful and comprehensive platform designed to accelerate the development and deployment of AI-powered robots. It serves as a cornerstone for what is increasingly known as Physical AI, which focuses on intelligent systems capable of interacting with and perceiving the real world, rather than just operating in digital domains.","source":"@site/docs/module-3-ai-robot-brain/01-isaac-overview.md","sourceDirName":"module-3-ai-robot-brain","slug":"/module-3-ai-robot-brain/isaac-overview","permalink":"/docs/module-3-ai-robot-brain/isaac-overview","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-3-ai-robot-brain/01-isaac-overview.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 5: Visualizing the Robot in Unity","permalink":"/docs/module-2/unity-visualization"},"next":{"title":"Isaac Sim: Photorealistic Simulation and Synthetic Data","permalink":"/docs/module-3-ai-robot-brain/isaac-sim"}},{"id":"module-3-ai-robot-brain/isaac-ros","title":"Isaac ROS: VSLAM and Perception Acceleration","description":"NVIDIA Isaac ROS is a collection of hardware-accelerated packages for ROS 2, specifically designed to boost the performance of robotics applications. It leverages the power of NVIDIA GPUs to provide significant acceleration for computationally intensive tasks, particularly in the areas of perception and navigation, which are critical for autonomous robots, including humanoid platforms.","source":"@site/docs/module-3-ai-robot-brain/03-isaac-ros.md","sourceDirName":"module-3-ai-robot-brain","slug":"/module-3-ai-robot-brain/isaac-ros","permalink":"/docs/module-3-ai-robot-brain/isaac-ros","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-3-ai-robot-brain/03-isaac-ros.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Isaac Sim: Photorealistic Simulation and Synthetic Data","permalink":"/docs/module-3-ai-robot-brain/isaac-sim"},"next":{"title":"Chapter 9: \"Nav2: Path Planning for Humanoid Robots\"","permalink":"/docs/module-3-ai-robot-brain/nav2-humanoids"}},{"id":"module-3-ai-robot-brain/isaac-sim","title":"Isaac Sim: Photorealistic Simulation and Synthetic Data","description":"NVIDIA Isaac Sim is a powerful and scalable robotics simulation application built on the NVIDIA Omniverse platform. It is a critical component in the development of AI-powered robots, offering a highly realistic virtual environment for design, testing, and training without the constraints and costs associated with physical hardware.","source":"@site/docs/module-3-ai-robot-brain/02-isaac-sim.md","sourceDirName":"module-3-ai-robot-brain","slug":"/module-3-ai-robot-brain/isaac-sim","permalink":"/docs/module-3-ai-robot-brain/isaac-sim","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-3-ai-robot-brain/02-isaac-sim.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 6: Understanding NVIDIA Isaac and Physical AI","permalink":"/docs/module-3-ai-robot-brain/isaac-overview"},"next":{"title":"Isaac ROS: VSLAM and Perception Acceleration","permalink":"/docs/module-3-ai-robot-brain/isaac-ros"}},{"id":"module-3-ai-robot-brain/nav2-humanoids","title":"Chapter 9: \"Nav2: Path Planning for Humanoid Robots\"","description":"Nav2 (Navigation2) is the ROS 2-native navigation stack, providing a complete framework for autonomous mobile robots to navigate complex environments. While initially designed for wheeled and tracked robots, its modular architecture and advanced capabilities make it adaptable and highly relevant for path planning in more complex platforms, such as humanoid robots.","source":"@site/docs/module-3-ai-robot-brain/04-nav2-humanoids.md","sourceDirName":"module-3-ai-robot-brain","slug":"/module-3-ai-robot-brain/nav2-humanoids","permalink":"/docs/module-3-ai-robot-brain/nav2-humanoids","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-3-ai-robot-brain/04-nav2-humanoids.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Isaac ROS: VSLAM and Perception Acceleration","permalink":"/docs/module-3-ai-robot-brain/isaac-ros"},"next":{"title":"Chapter 10:  Vision-Language-Action (VLA)","permalink":"/docs/module-4-vla/vla-overview"}},{"id":"module-4-vla/autonomous-pipeline","title":"Chapter 13: Capstone: Autonomous Humanoid Pipeline","description":"This chapter covers the integration of Voice-to-Action and LLM Task Planning into an end-to-end autonomous pipeline for humanoid robots.","source":"@site/docs/module-4-vla/autonomous-pipeline.md","sourceDirName":"module-4-vla","slug":"/module-4-vla/autonomous-pipeline","permalink":"/docs/module-4-vla/autonomous-pipeline","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-4-vla/autonomous-pipeline.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 12: LLM-Based Task Planning to ROS 2","permalink":"/docs/module-4-vla/llm-task-planning"}},{"id":"module-4-vla/llm-task-planning","title":"Chapter 12: LLM-Based Task Planning to ROS 2","description":"This chapter covers using Large Language Models (LLMs) for task planning and generating ROS 2 actions.","source":"@site/docs/module-4-vla/llm-task-planning.md","sourceDirName":"module-4-vla","slug":"/module-4-vla/llm-task-planning","permalink":"/docs/module-4-vla/llm-task-planning","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-4-vla/llm-task-planning.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 11: Voice-to-Action with Whisper","permalink":"/docs/module-4-vla/voice-to-action"},"next":{"title":"Chapter 13: Capstone: Autonomous Humanoid Pipeline","permalink":"/docs/module-4-vla/autonomous-pipeline"}},{"id":"module-4-vla/vla-overview","title":"Chapter 10:  Vision-Language-Action (VLA)","description":"This module introduces Vision-Language-Action (VLA) systems for humanoid robots.","source":"@site/docs/module-4-vla/vla-overview.md","sourceDirName":"module-4-vla","slug":"/module-4-vla/vla-overview","permalink":"/docs/module-4-vla/vla-overview","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-4-vla/vla-overview.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 9: \"Nav2: Path Planning for Humanoid Robots\"","permalink":"/docs/module-3-ai-robot-brain/nav2-humanoids"},"next":{"title":"Chapter 11: Voice-to-Action with Whisper","permalink":"/docs/module-4-vla/voice-to-action"}},{"id":"module-4-vla/voice-to-action","title":"Chapter 11: Voice-to-Action with Whisper","description":"This chapter covers converting voice commands into robot actions using Whisper.","source":"@site/docs/module-4-vla/voice-to-action.md","sourceDirName":"module-4-vla","slug":"/module-4-vla/voice-to-action","permalink":"/docs/module-4-vla/voice-to-action","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-4-vla/voice-to-action.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 10:  Vision-Language-Action (VLA)","permalink":"/docs/module-4-vla/vla-overview"},"next":{"title":"Chapter 12: LLM-Based Task Planning to ROS 2","permalink":"/docs/module-4-vla/llm-task-planning"}}],"drafts":[],"sidebars":{"tutorialSidebar":[{"type":"category","label":"Module 1 - ROS 2 Nervous System","items":[{"type":"doc","id":"module-1-ros2-nervous-system/ros2-fundamentals"},{"type":"doc","id":"module-1-ros2-nervous-system/python-agents-with-rclpy"},{"type":"doc","id":"module-1-ros2-nervous-system/humanoid-robot-description-urdf"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 2 - The Digital Twin","items":[{"type":"doc","id":"module-2/digital-twins"},{"type":"doc","id":"module-2/unity-visualization"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 3 - The AI-Robot Brain (NVIDIA Isaac)","items":[{"type":"doc","id":"module-3-ai-robot-brain/isaac-overview"},{"type":"doc","id":"module-3-ai-robot-brain/isaac-sim"},{"type":"doc","id":"module-3-ai-robot-brain/isaac-ros"},{"type":"doc","id":"module-3-ai-robot-brain/nav2-humanoids"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 4 - Vision-Language-Action (VLA)","items":[{"type":"doc","id":"module-4-vla/vla-overview"},{"type":"doc","id":"module-4-vla/voice-to-action"},{"type":"doc","id":"module-4-vla/llm-task-planning"},{"type":"doc","id":"module-4-vla/autonomous-pipeline"}],"collapsed":true,"collapsible":true}]}}]}},"docusaurus-plugin-content-blog":{"default":{"blogSidebarTitle":"Recent posts","blogPosts":[{"id":"welcome","metadata":{"permalink":"/blog/welcome","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2021-08-26-welcome/index.md","source":"@site/blog/2021-08-26-welcome/index.md","title":"Welcome","description":"Docusaurus blogging features are powered by the blog plugin.","date":"2021-08-26T00:00:00.000Z","tags":[{"inline":false,"label":"Facebook","permalink":"/blog/tags/facebook","description":"Facebook tag description"},{"inline":false,"label":"Hello","permalink":"/blog/tags/hello","description":"Hello tag description"},{"inline":false,"label":"Docusaurus","permalink":"/blog/tags/docusaurus","description":"Docusaurus tag description"}],"readingTime":0.56,"hasTruncateMarker":true,"authors":[{"name":"Sébastien Lorber","title":"Docusaurus maintainer","url":"https://sebastienlorber.com","page":{"permalink":"/blog/authors/all-sebastien-lorber-articles"},"socials":{"x":"https://x.com/sebastienlorber","linkedin":"https://www.linkedin.com/in/sebastienlorber/","github":"https://github.com/slorber","newsletter":"https://thisweekinreact.com"},"imageURL":"https://github.com/slorber.png","key":"slorber"},{"name":"Yangshun Tay","title":"Ex-Meta Staff Engineer, Co-founder GreatFrontEnd","url":"https://linkedin.com/in/yangshun","page":{"permalink":"/blog/authors/yangshun"},"socials":{"x":"https://x.com/yangshunz","linkedin":"https://www.linkedin.com/in/yangshun/","github":"https://github.com/yangshun","newsletter":"https://www.greatfrontend.com"},"imageURL":"https://github.com/yangshun.png","key":"yangshun"}],"frontMatter":{"slug":"welcome","title":"Welcome","authors":["slorber","yangshun"],"tags":["facebook","hello","docusaurus"]},"unlisted":false,"nextItem":{"title":"MDX Blog Post","permalink":"/blog/mdx-blog-post"}},"content":"[Docusaurus blogging features](https://docusaurus.io/docs/blog) are powered by the [blog plugin](https://docusaurus.io/docs/api/plugins/@docusaurus/plugin-content-blog).\n\nHere are a few tips you might find useful.\n\n<!-- truncate -->\n\nSimply add Markdown files (or folders) to the `blog` directory.\n\nRegular blog authors can be added to `authors.yml`.\n\nThe blog post date can be extracted from filenames, such as:\n\n- `2019-05-30-welcome.md`\n- `2019-05-30-welcome/index.md`\n\nA blog post folder can be convenient to co-locate blog post images:\n\n![Docusaurus Plushie](./docusaurus-plushie-banner.jpeg)\n\nThe blog supports tags as well!\n\n**And if you don't want a blog**: just delete this directory, and use `blog: false` in your Docusaurus config."},{"id":"mdx-blog-post","metadata":{"permalink":"/blog/mdx-blog-post","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2021-08-01-mdx-blog-post.mdx","source":"@site/blog/2021-08-01-mdx-blog-post.mdx","title":"MDX Blog Post","description":"Blog posts support Docusaurus Markdown features, such as MDX.","date":"2021-08-01T00:00:00.000Z","tags":[{"inline":false,"label":"Docusaurus","permalink":"/blog/tags/docusaurus","description":"Docusaurus tag description"}],"readingTime":0.27,"hasTruncateMarker":true,"authors":[{"name":"Sébastien Lorber","title":"Docusaurus maintainer","url":"https://sebastienlorber.com","page":{"permalink":"/blog/authors/all-sebastien-lorber-articles"},"socials":{"x":"https://x.com/sebastienlorber","linkedin":"https://www.linkedin.com/in/sebastienlorber/","github":"https://github.com/slorber","newsletter":"https://thisweekinreact.com"},"imageURL":"https://github.com/slorber.png","key":"slorber"}],"frontMatter":{"slug":"mdx-blog-post","title":"MDX Blog Post","authors":["slorber"],"tags":["docusaurus"]},"unlisted":false,"prevItem":{"title":"Welcome","permalink":"/blog/welcome"},"nextItem":{"title":"Long Blog Post","permalink":"/blog/long-blog-post"}},"content":"Blog posts support [Docusaurus Markdown features](https://docusaurus.io/docs/markdown-features), such as [MDX](https://mdxjs.com/).\n\n:::tip\n\nUse the power of React to create interactive blog posts.\n\n:::\n\n{/* truncate */}\n\nFor example, use JSX to create an interactive button:\n\n```js\n<button onClick={() => alert('button clicked!')}>Click me!</button>\n```\n\n<button onClick={() => alert('button clicked!')}>Click me!</button>"},{"id":"long-blog-post","metadata":{"permalink":"/blog/long-blog-post","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2019-05-29-long-blog-post.md","source":"@site/blog/2019-05-29-long-blog-post.md","title":"Long Blog Post","description":"This is the summary of a very long blog post,","date":"2019-05-29T00:00:00.000Z","tags":[{"inline":false,"label":"Hello","permalink":"/blog/tags/hello","description":"Hello tag description"},{"inline":false,"label":"Docusaurus","permalink":"/blog/tags/docusaurus","description":"Docusaurus tag description"}],"readingTime":2.04,"hasTruncateMarker":true,"authors":[{"name":"Yangshun Tay","title":"Ex-Meta Staff Engineer, Co-founder GreatFrontEnd","url":"https://linkedin.com/in/yangshun","page":{"permalink":"/blog/authors/yangshun"},"socials":{"x":"https://x.com/yangshunz","linkedin":"https://www.linkedin.com/in/yangshun/","github":"https://github.com/yangshun","newsletter":"https://www.greatfrontend.com"},"imageURL":"https://github.com/yangshun.png","key":"yangshun"}],"frontMatter":{"slug":"long-blog-post","title":"Long Blog Post","authors":"yangshun","tags":["hello","docusaurus"]},"unlisted":false,"prevItem":{"title":"MDX Blog Post","permalink":"/blog/mdx-blog-post"},"nextItem":{"title":"First Blog Post","permalink":"/blog/first-blog-post"}},"content":"This is the summary of a very long blog post,\n\nUse a `<!--` `truncate` `-->` comment to limit blog post size in the list view.\n\n<!-- truncate -->\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet"},{"id":"first-blog-post","metadata":{"permalink":"/blog/first-blog-post","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2019-05-28-first-blog-post.md","source":"@site/blog/2019-05-28-first-blog-post.md","title":"First Blog Post","description":"Lorem ipsum dolor sit amet...","date":"2019-05-28T00:00:00.000Z","tags":[{"inline":false,"label":"Hola","permalink":"/blog/tags/hola","description":"Hola tag description"},{"inline":false,"label":"Docusaurus","permalink":"/blog/tags/docusaurus","description":"Docusaurus tag description"}],"readingTime":0.13,"hasTruncateMarker":true,"authors":[{"name":"Sébastien Lorber","title":"Docusaurus maintainer","url":"https://sebastienlorber.com","page":{"permalink":"/blog/authors/all-sebastien-lorber-articles"},"socials":{"x":"https://x.com/sebastienlorber","linkedin":"https://www.linkedin.com/in/sebastienlorber/","github":"https://github.com/slorber","newsletter":"https://thisweekinreact.com"},"imageURL":"https://github.com/slorber.png","key":"slorber"},{"name":"Yangshun Tay","title":"Ex-Meta Staff Engineer, Co-founder GreatFrontEnd","url":"https://linkedin.com/in/yangshun","page":{"permalink":"/blog/authors/yangshun"},"socials":{"x":"https://x.com/yangshunz","linkedin":"https://www.linkedin.com/in/yangshun/","github":"https://github.com/yangshun","newsletter":"https://www.greatfrontend.com"},"imageURL":"https://github.com/yangshun.png","key":"yangshun"}],"frontMatter":{"slug":"first-blog-post","title":"First Blog Post","authors":["slorber","yangshun"],"tags":["hola","docusaurus"]},"unlisted":false,"prevItem":{"title":"Long Blog Post","permalink":"/blog/long-blog-post"}},"content":"Lorem ipsum dolor sit amet...\n\n<!-- truncate -->\n\n...consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet"}],"blogListPaginated":[{"items":["welcome","mdx-blog-post","long-blog-post","first-blog-post"],"metadata":{"permalink":"/blog","page":1,"postsPerPage":10,"totalPages":1,"totalCount":4,"blogDescription":"Blog","blogTitle":"Blog"}}],"blogTags":{"/blog/tags/facebook":{"inline":false,"label":"Facebook","permalink":"/blog/tags/facebook","description":"Facebook tag description","items":["welcome"],"pages":[{"items":["welcome"],"metadata":{"permalink":"/blog/tags/facebook","page":1,"postsPerPage":10,"totalPages":1,"totalCount":1,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/blog/tags/hello":{"inline":false,"label":"Hello","permalink":"/blog/tags/hello","description":"Hello tag description","items":["welcome","long-blog-post"],"pages":[{"items":["welcome","long-blog-post"],"metadata":{"permalink":"/blog/tags/hello","page":1,"postsPerPage":10,"totalPages":1,"totalCount":2,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/blog/tags/docusaurus":{"inline":false,"label":"Docusaurus","permalink":"/blog/tags/docusaurus","description":"Docusaurus tag description","items":["welcome","mdx-blog-post","long-blog-post","first-blog-post"],"pages":[{"items":["welcome","mdx-blog-post","long-blog-post","first-blog-post"],"metadata":{"permalink":"/blog/tags/docusaurus","page":1,"postsPerPage":10,"totalPages":1,"totalCount":4,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/blog/tags/hola":{"inline":false,"label":"Hola","permalink":"/blog/tags/hola","description":"Hola tag description","items":["first-blog-post"],"pages":[{"items":["first-blog-post"],"metadata":{"permalink":"/blog/tags/hola","page":1,"postsPerPage":10,"totalPages":1,"totalCount":1,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false}},"blogTagsListPath":"/blog/tags","authorsMap":{"yangshun":{"name":"Yangshun Tay","title":"Ex-Meta Staff Engineer, Co-founder GreatFrontEnd","url":"https://linkedin.com/in/yangshun","page":{"permalink":"/blog/authors/yangshun"},"socials":{"x":"https://x.com/yangshunz","linkedin":"https://www.linkedin.com/in/yangshun/","github":"https://github.com/yangshun","newsletter":"https://www.greatfrontend.com"},"imageURL":"https://github.com/yangshun.png","key":"yangshun"},"slorber":{"name":"Sébastien Lorber","title":"Docusaurus maintainer","url":"https://sebastienlorber.com","page":{"permalink":"/blog/authors/all-sebastien-lorber-articles"},"socials":{"x":"https://x.com/sebastienlorber","linkedin":"https://www.linkedin.com/in/sebastienlorber/","github":"https://github.com/slorber","newsletter":"https://thisweekinreact.com"},"imageURL":"https://github.com/slorber.png","key":"slorber"}}}},"docusaurus-plugin-content-pages":{"default":[{"type":"jsx","permalink":"/","source":"@site/src/pages/index.tsx"},{"type":"mdx","permalink":"/markdown-page","source":"@site/src/pages/markdown-page.md","title":"Markdown page example","description":"You don't need React to write simple standalone pages.","frontMatter":{"title":"Markdown page example"},"unlisted":false}]},"docusaurus-plugin-debug":{},"docusaurus-plugin-svgr":{},"docusaurus-theme-classic":{},"docusaurus-bootstrap-plugin":{},"docusaurus-mdx-fallback-plugin":{}}}